Table of Content
---
- [AI Usage Policy for BigBio Lab](#ai-usage-policy-for-bigbio-lab)
    - [1. Purpose and Scope](#1-purpose-and-scope)
    - [2. Acceptable Use of AI Tools](#2-acceptable-use-of-ai-tools)
      - [a. Research and Development](#a-research-and-development)
      - [b. Code Development and Review](#b-code-development-and-review)
      - [c. Data Analysis](#c-data-analysis)
      - [d. Writing and Documentation](#d-writing-and-documentation)
    - [3. Prohibited Uses](#3-prohibited-uses)
      - [a. Confidential Data](#a-confidential-data)
      - [b. Patient and Health Data](#b-patient-and-health-data)
      - [c. Proprietary Research](#c-proprietary-research)
      - [d. Academic Integrity](#d-academic-integrity)
    - [4. Data Security and Privacy](#4-data-security-and-privacy)
      - [a. Data Classification](#a-data-classification)
      - [b. Approved AI Tools](#b-approved-ai-tools)
      - [c. Data Anonymization](#c-data-anonymization)
    - [5. Attribution and Transparency](#5-attribution-and-transparency)
      - [a. Disclosure in Publications](#a-disclosure-in-publications)
      - [b. Code Documentation](#b-code-documentation)
      - [c. Peer Review](#c-peer-review)
    - [6. Quality Control and Validation](#6-quality-control-and-validation)
      - [a. Human Oversight](#a-human-oversight)
      - [b. Verification of Results](#b-verification-of-results)
      - [c. Critical Review](#c-critical-review)
    - [7. Intellectual Property](#7-intellectual-property)
      - [a. Ownership](#a-ownership)
      - [b. Third-Party Rights](#b-third-party-rights)
    - [8. Reporting and Accountability](#8-reporting-and-accountability)
      - [a. Immediate Reporting](#a-immediate-reporting)
      - [b. Regular Audits](#b-regular-audits)
    - [9. Degrees of Punishment for Violations](#9-degrees-of-punishment-for-violations)
      - [a. First Offense](#a-first-offense)
      - [b. Second Offense](#b-second-offense)
      - [c. Third Offense](#c-third-offense)
      - [d. Severe Violations](#d-severe-violations)
    - [10. Training and Education](#10-training-and-education)
    - [11. Review and Update](#11-review-and-update)

# AI Usage Policy for BigBio Lab

### 1. Purpose and Scope
The purpose of this AI usage policy is to establish guidelines for the responsible and ethical use of artificial intelligence tools by BigBio Lab team members. This policy applies to all individuals affiliated with BigBio Lab, including researchers, students, staff, and collaborators, when using AI tools for research, development, analysis, writing, or any other lab-related activities.

### 2. Acceptable Use of AI Tools
#### a. Research and Development
AI tools may be used to enhance research productivity, generate hypotheses, perform literature reviews, and assist in experimental design. Team members should use AI as a supportive tool while maintaining critical thinking and scientific rigor.

#### b. Code Development and Review
AI-assisted coding tools (e.g., GitHub Copilot, ChatGPT, Claude) may be used to:
- Generate code snippets and boilerplate code
- Debug and optimize existing code
- Learn new programming languages and frameworks
- Document code and create comments

All AI-generated code must be reviewed, tested, and understood by the team member before integration.

#### c. Data Analysis
AI tools may be used for data preprocessing, statistical analysis, and visualization, provided that:
- The methodologies are transparent and reproducible
- Results are validated through appropriate statistical methods
- No sensitive or confidential data is uploaded to external AI services

#### d. Writing and Documentation
AI tools may assist with:
- Drafting documentation, reports, and presentations
- Grammar and style improvement
- Translating technical content
- Generating initial drafts of standard sections (e.g., methods descriptions)

Final content must be thoroughly reviewed, edited, and approved by the responsible team member.

### 3. Prohibited Uses
#### a. Confidential Data
Never upload confidential, proprietary, or sensitive lab data to public AI services without explicit approval. This includes unpublished research data, internal communications, and strategic planning documents.

#### b. Patient and Health Data
Strictly prohibited: uploading any patient data, health records, genetic information, or personally identifiable information (PII) to external AI tools, even if anonymized, unless using approved, HIPAA-compliant AI services.

#### c. Proprietary Research
Do not share unpublished research findings, novel methodologies, or proprietary algorithms with AI tools that may store or learn from the data.

#### d. Academic Integrity
AI tools must not be used to:
- Generate entire manuscripts or research papers without significant human contribution
- Fabricate data or results
- Plagiarize or misrepresent the work of others
- Complete assignments or examinations in violation of academic integrity policies

### 4. Data Security and Privacy
#### a. Data Classification
Team members must classify data before using AI tools:
- **Public**: Can be used with any AI tool
- **Internal**: Only with approved, secure AI tools
- **Confidential**: Requires special approval and privacy-preserving methods
- **Restricted**: Never use with external AI tools

#### b. Approved AI Tools
The lab maintains a list of approved AI tools that meet security and privacy standards. Team members should consult with lab leadership before using new AI services.

#### c. Data Anonymization
When using AI tools with internal data, ensure proper anonymization and de-identification. Remove all identifiers, metadata, and contextual information that could be used to re-identify subjects.

### 5. Attribution and Transparency
#### a. Disclosure in Publications
When AI tools significantly contribute to research, their use must be disclosed in the methods section or acknowledgments. Specify:
- Which AI tools were used
- For what specific purposes
- How the output was validated

#### b. Code Documentation
AI-generated code should be documented with comments indicating:
- The AI tool used
- The original prompt or requirement
- Any modifications made to the generated code

#### c. Peer Review
Be transparent with collaborators and reviewers about the use of AI tools in research processes.

### 6. Quality Control and Validation
#### a. Human Oversight
All AI-generated content, code, and analyses must undergo human review and validation. Team members are responsible for the accuracy and quality of any AI-assisted work.

#### b. Verification of Results
AI-generated results, particularly in data analysis and modeling, must be:
- Cross-validated using independent methods
- Tested for reproducibility
- Evaluated for biological and scientific plausibility

#### c. Critical Review
Team members should critically evaluate AI outputs for:
- Bias and fairness
- Scientific accuracy
- Methodological soundness
- Ethical implications

### 7. Intellectual Property
#### a. Ownership
Team members must understand that:
- AI-generated content may not be copyrightable in some jurisdictions
- The lab retains ownership of all work products, including AI-assisted work
- Using AI tools does not transfer intellectual property rights

#### b. Third-Party Rights
Ensure that AI-generated content does not infringe on third-party copyrights, patents, or other intellectual property rights.

### 8. Reporting and Accountability
#### a. Immediate Reporting
Team members must immediately report:
- Accidental upload of confidential or sensitive data to AI tools
- Security breaches or data leaks
- Ethical concerns regarding AI use
- Potential violations of this policy

#### b. Regular Audits
The lab will conduct periodic audits of AI tool usage to ensure compliance with this policy and identify areas for improvement.

### 9. Degrees of Punishment for Violations
#### a. First Offense
A verbal warning and mandatory training will be issued. The individual will receive guidance on proper AI tool usage and must complete a review of this policy.

#### b. Second Offense
A written warning will be issued and documented. The individual may be temporarily restricted from using certain AI tools and must complete additional training on data security and research ethics.

#### c. Third Offense
Serious disciplinary action, including:
- Suspension of AI tool access
- Removal from specific projects
- Temporary suspension from lab activities
- Required ethics training and supervision

#### d. Severe Violations
For severe violations involving:
- Disclosure of patient data or PII
- Academic misconduct or fraud
- Intentional security breaches
- Violations of legal or regulatory requirements

Consequences may include:
- Immediate termination of association with BigBio Lab
- Reporting to institutional authorities
- Notification to collaborators and funding agencies
- Legal action if required by law

### 10. Training and Education
All lab members must complete AI usage training that covers:
- Ethical use of AI tools
- Data security and privacy
- Academic integrity
- Tool-specific training for approved AI services

Training must be completed within the first month of joining the lab and updated annually.

### 11. Review and Update
This AI usage policy will be reviewed and updated at least annually or as needed to reflect:
- New AI technologies and tools
- Changes in regulations and institutional policies
- Emerging ethical considerations
- Feedback from lab members and collaborators

Team members will be notified of any changes and required to acknowledge their understanding of updated policies.

By adhering to this AI usage policy, BigBio Lab aims to leverage artificial intelligence responsibly and ethically while maintaining the highest standards of scientific integrity, data security, and research excellence in health data science, computational biology, and genomics.

**Date of Implementation:** 5 January, 2026
**Review Date:** 5 January, 2027
